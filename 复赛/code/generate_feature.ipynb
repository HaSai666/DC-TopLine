{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import datetime\n",
    "from tqdm import trange\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import warnings\n",
    "import time\n",
    "from numpy import *\n",
    "from sklearn.linear_model import  *\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from xgboost import *\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.linear_model import  *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sympy import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={}\n",
    "dict['四川省']=32617\n",
    "dict['安徽省']=32001\n",
    "dict['福建省']=58145\n",
    "dict['河北省']=38909\n",
    "dict['贵州省']=23151\n",
    "dict['山东省']=56885\n",
    "dict['黑龙江省']=37697\n",
    "dict['广东省']=58833\n",
    "dict['北京']=94648\n",
    "dict['重庆']=43223\n",
    "dict['浙江省']=68805\n",
    "dict['辽宁省']=61996\n",
    "dict['河南省']=34211\n",
    "dict['海南省']=35663\n",
    "dict['湖南省']=36943\n",
    "dict['甘肃省']=24539\n",
    "dict['陕西省']=43117\n",
    "dict['内蒙古自治区']=67836\n",
    "dict['江苏省']=75354\n",
    "dict['天津']=100105\n",
    "dict['上海']=90993\n",
    "dict['云南省']=25322\n",
    "dict['湖北省']=42826\n",
    "dict['江西省']=31930\n",
    "dict['吉林省']=47428\n",
    "dict['山西省']=34984\n",
    "dict['宁夏回族自治区']=39613\n",
    "dict['西藏自治区']=26326\n",
    "dict['新疆维吾尔自治区']=37553\n",
    "dict['广西壮族自治区']=30741\n",
    "dict['青海省']=36875\n",
    "ave=0\n",
    "total=0\n",
    "for key in dict:\n",
    "    total+=dict[key]\n",
    "ave = total/len(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_month(s):\n",
    "    return s.apply(lambda x: int(x.split('-')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据\n",
    "temp1 = pd.read_csv('../Data/round1_diac2019_train.csv',low_memory=False)\n",
    "temp2 = pd.read_csv('../Data/round2_diac2019_train.csv',low_memory=False)\n",
    "temp = temp1.append(temp2)\n",
    "temp.to_csv('../Data/round12_diac2019_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1826575, 1)\n"
     ]
    }
   ],
   "source": [
    "# 读取原始数据\n",
    "trian = pd.read_csv('../Data/round12_diac2019_train.csv',low_memory=False) # 读取初赛加复赛数据\n",
    "trian1 = pd.read_csv('../Data/round2_diac2019_train.csv',low_memory=False) #读取复赛数据\n",
    "all_customer = pd.DataFrame(trian[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "print(all_customer.shape)\n",
    "\n",
    "trian['order_pay_time'] = pd.to_datetime(trian['order_pay_time'])\n",
    "trian['order_pay_date'] = trian['order_pay_time'].dt.date\n",
    "trian1['order_pay_time'] = pd.to_datetime(trian1['order_pay_time'])\n",
    "trian1['order_pay_date'] = trian1['order_pay_time'].dt.date\n",
    "#validata_date_begin = trian['order_pay_date'].max() - datetime.timedelta(days=180)\n",
    "\n",
    "trian['order_month'] = extract_month(trian['order_pay_date'].astype(str))\n",
    "trian1['order_month'] = extract_month(trian['order_pay_date'].astype(str))\n",
    "\n",
    "trian[\"GDP\"]=ave\n",
    "trian1[\"GDP\"]=ave\n",
    "for key in dict:\n",
    "    trian[\"GDP\"][trian[\"customer_province\"]==key]=dict[key]\n",
    "    trian1[\"GDP\"][trian[\"customer_province\"]==key]=dict[key]\n",
    "\n",
    "count_fea=['order_month','goods_id']\n",
    "for feat in count_fea:\n",
    "    col_name = '{}_count'.format(feat)\n",
    "    trian[col_name] = trian[feat].map(trian[feat].value_counts().astype(int))\n",
    "    trian.loc[trian[col_name] < 2, feat] = -1\n",
    "    trian[feat] += 1\n",
    "    trian[col_name] = trian[feat].map(trian[feat].value_counts().astype(int))\n",
    "    trian[col_name] = (trian[col_name] - trian[col_name].min()) / (trian[col_name].max() - trian[col_name].min())\n",
    "    \n",
    "    trian1[col_name] = trian1[feat].map(trian1[feat].value_counts().astype(int))\n",
    "    trian1.loc[trian1[col_name] < 2, feat] = -1\n",
    "    trian1[feat] += 1\n",
    "    trian1[col_name] = trian1[feat].map(trian1[feat].value_counts().astype(int))\n",
    "    trian1[col_name] = (trian1[col_name] - trian1[col_name].min()) / (trian1[col_name].max() - trian1[col_name].min())\n",
    "\n",
    "train_history = trian[(trian['order_pay_date'].astype(str)<='2013-10-31')]\n",
    "online_history = trian[(trian['order_pay_date'].astype(str)<='2013-12-31')]\n",
    "train_label = trian[trian['order_pay_date'].astype(str)>='2013-11-01']\n",
    "online_history1 = trian1[(trian1['order_pay_date'].astype(str)<='2013-12-31')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 相关数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除类别唯一的特征\n",
    "for df in [train_history,online_history,online_history1]:\n",
    "    df.drop(['order_detail_id','order_id','goods_id','member_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_customer_rate 0.9493003981690669\n",
      "order_detail_goods_num 0.9538791201830489\n",
      "order_detail_status 0.9102991657674617\n",
      "order_status 0.9126025565943487\n",
      "is_customer_rate 0.9408900062182921\n",
      "order_detail_goods_num 0.9584204020672824\n",
      "order_detail_status 0.9049027110138655\n",
      "order_status 0.9070163430226283\n",
      "order_status 0.903986967045243\n",
      "is_customer_rate 0.9697505120089369\n",
      "order_detail_status 0.9013975051200893\n",
      "order_detail_goods_num 0.9406911189722584\n"
     ]
    }
   ],
   "source": [
    "# 删除某一类别占比超过90%的列\n",
    "for df in [train_history,online_history,online_history1]:\n",
    "    good_cols = list(df.columns)\n",
    "    for col in df.columns:\n",
    "        rate = df[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "        if rate > 0.9:\n",
    "            good_cols.remove(col)\n",
    "            print(col,rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除异常值\n",
    "train_history = train_history[train_history['order_amount']<=2000]\n",
    "train_history = train_history[train_history['order_total_payment']<=2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加一些特征 \n",
    "train_history['goods_num'] = train_history['order_total_num']*train_history['order_count']\n",
    "train_label['goods_num'] = train_label['order_total_num']*train_label['order_count']\n",
    "online_history['goods_num'] = online_history['order_total_num']*online_history['order_count']\n",
    "online_history1['goods_num'] = online_history1['order_total_num']*online_history1['order_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_history,train_label,online_history,online_history1]:\n",
    "    df['log_order_amount'] = np.log(df['order_amount'].values+1)\n",
    "    df['log_goods_price'] = np.log(df['goods_price'].values+1)\n",
    "    df['pay_deleta_time'] = ( pd.to_datetime(df['goods_list_time'])  - pd.to_datetime(df['order_pay_time']))\n",
    "    df['goods_list_time'] = ( pd.to_datetime(df['goods_delist_time'])-pd.to_datetime(df['goods_list_time']))\n",
    "    df['pay_deleta_time'] = df['pay_deleta_time'].dt.days+1\n",
    "    df['goods_list_time'] = df['goods_list_time'].dt.days+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单的特征生成部分代码\n",
    "def make_feature_and_label(date1,date2,isSubmit):\n",
    "    date1['count'] = 1\n",
    "    # 统计这个用户出现了多少次\n",
    "    customer_id = date1.groupby(['customer_id'],as_index=False)['count'].agg({'count':'count'})\n",
    "    # 统计这个用户购买商品的价格信息\n",
    "    good_price = date1.groupby(['customer_id'],as_index=False)['goods_price'].agg({'goods_price_max':'max',\n",
    "                                                                                    'goods_price_min':'min',\n",
    "                                                                                    'goods_price_mean':'mean',\n",
    "                                                                                    'goods_price_sum':'sum'})\n",
    "    \n",
    "    #添加用户性别\n",
    "    customer_gender= date1.groupby(['customer_id'],as_index=False)['customer_gender'].mean()\n",
    "    customer_gender = customer_gender.fillna(0)\n",
    "    \n",
    "    \n",
    "    class_le = LabelEncoder()    \n",
    "    #添加用户所属省份\n",
    "    date1['customer_province'].fillna('未知',inplace=True)\n",
    "    date1['customer_province_l'] = class_le.fit_transform(date1['customer_province'])\n",
    "    customer_province_l = date1.groupby(['customer_id'],as_index=False)['customer_province_l'].max()\n",
    "    \n",
    "    #gdp\n",
    "    gdp = date1.groupby(['customer_id'],as_index=False)['GDP'].max()\n",
    "    #月份特征\n",
    "    order_month_count = date1.groupby(['customer_id'],as_index=False)['order_month_count'].max()\n",
    "    \n",
    "    #商品特征\n",
    "    goods_id_count = date1.groupby(['customer_id'],as_index=False)['goods_id_count'].max()\n",
    "    \n",
    "    #统计该用户是不是会员\n",
    "    is_member = date1.groupby(['customer_id'],as_index=False)['is_member_actived'].median()\n",
    "    is_member = is_member.fillna(0)\n",
    "    \n",
    "    #统计用户购物车内商品数量\n",
    "    goods = date1.groupby(['customer_id'],as_index=False)['order_count'].max()\n",
    "    goods=goods.fillna(0)\n",
    "    \n",
    "    #统计用户花了多少钱及多少个\n",
    "    order_total_num = date1.groupby(['customer_id'],as_index=False)['order_total_num'].mean()\n",
    "    order_total_num = order_total_num.fillna(0)\n",
    "    \n",
    "    order_count = date1.groupby(['customer_id'],as_index=False)['order_count'].mean()\n",
    "    order_count = order_count.fillna(0)\n",
    "    \n",
    "    total_num = order_count*order_total_num\n",
    "    \n",
    "    order_amount = date1.groupby(['customer_id'],as_index=False)['order_amount'].max()\n",
    "    order_amount = order_amount.fillna(0)\n",
    "    \n",
    "    order_total_payment = date1.groupby(['customer_id'],as_index=False)['order_total_payment'].mean()\n",
    "    order_total_payment = order_total_payment.fillna(0)\n",
    "    order_total_payment_level = order_total_payment\n",
    "    order_total_payment_level['order_total_payment'] = order_total_payment['order_total_payment']>293\n",
    "      \n",
    "    \n",
    "    goods_num = date1.groupby(['customer_id'],as_index=False)['goods_num'].mean()\n",
    "    goods_num.fillna(0)\n",
    "    \n",
    "    goods_list_time = date1.groupby(['customer_id'],as_index=False)['goods_list_time'].agg({'goods_list_time_last':'max',\n",
    "                                                                                           'goods_list_time_mean':'mean'})\n",
    "    \n",
    "        \n",
    "    pay_deleta_time = date1.groupby(['customer_id'],as_index=False)['pay_deleta_time'].agg({'pay_deleta_time_last':'max',\n",
    "                                                                                            'pay_deleta_time_first':'min',\n",
    "                                                                                           'pay_deleta_time_mean':'mean'})\n",
    "    \n",
    "    # 统计这个用户的订单最后一次购买时间\n",
    "    last_time = date1.groupby(['customer_id'],as_index=False)['order_pay_date'].agg({'order_pay_date_last':'max','order_pay_date_first':'min'})\n",
    "    # 当然这里面还可以构造更多的特征 \n",
    "    '''\n",
    "                    在这里疯狂加特征！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！\n",
    "    '''\n",
    "    data = pd.merge(customer_id,good_price,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,is_member,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,customer_gender,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,order_month_count,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,goods_id_count,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,gdp,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,pay_deleta_time,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,goods_list_time,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,goods_num,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,order_total_num,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,order_total_payment_level,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,customer_province_l,on=['customer_id'],how='left',copy=False)\n",
    "    data = pd.merge(data,last_time,on=['customer_id'],how='left',copy=False)\n",
    "    data['long_time'] = pd.to_datetime(data['order_pay_date_last']) - pd.to_datetime(data['order_pay_date_first'])\n",
    "    data['long_time'] = data['long_time'].dt.days + 1\n",
    "    del data['order_pay_date_first']\n",
    "    if isSubmit==False:\n",
    "        data['order_pay_date_last'] = pd.to_datetime(date2['order_pay_date'].min()) - pd.to_datetime(data['order_pay_date_last'])\n",
    "        data['order_pay_date_last'] = data['order_pay_date_last'].dt.days + 1\n",
    "        data['label'] = 0\n",
    "        data.loc[data['customer_id'].isin(list(date2['customer_id'].unique())),'label'] = 1\n",
    "        print(data['label'].mean())\n",
    "    else:\n",
    "        data['order_pay_date_last'] = pd.to_datetime('2013-12-31') - pd.to_datetime(data['order_pay_date_last'])\n",
    "        data['order_pay_date_last'] = data['order_pay_date_last'].dt.days + 1\n",
    "    print(data.shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20205092623801202\n",
      "(1824639, 23)\n",
      "(1826575, 22)\n",
      "(1826575, 22)\n"
     ]
    }
   ],
   "source": [
    "train = make_feature_and_label(train_history,train_label,False)\n",
    "submit = make_feature_and_label(online_history,None,True)\n",
    "submit1 = make_feature_and_label(online_history1,None,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../Feature/train.csv',index=False)\n",
    "submit.to_csv('../Feature/submit12.csv',index=False)\n",
    "submit1.to_csv('../Feature/submit2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
