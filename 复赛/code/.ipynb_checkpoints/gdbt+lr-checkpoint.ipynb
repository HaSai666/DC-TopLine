{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ksama\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看结果的最大值，最小值，平均值\n",
    "def show(result):\n",
    "    result = np.array(result)\n",
    "    print('max: ',str(max(result)))\n",
    "    print('min: ',str(min(result)))\n",
    "    print('mean: ',str((sum(result))/(len(result))))\n",
    "    print('var: ',str(np.var(result)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#官方的loss评估\n",
    "def logloss(y_true, y_pred,deta = 1.85, eps=1e-15):\n",
    "    # Prepare numpy array data\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    assert (len(y_true) and len(y_true) == len(y_pred))\n",
    "    # Clip y_pred between eps and 1-eps\n",
    "    p = np.clip(y_pred, eps, 1-eps)\n",
    "    loss = np.sum(- y_true * np.log(p) * deta - (1 - y_true) * np.log(1-p))\n",
    "    return loss / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "把结果保存成指定格式的文件\n",
    "示例：save_result2csv(y_submit,submit,'./round1_diac2019_test.csv')\n",
    "其中y_submit为模型输出结果，submit为读入数据时生成的一个变量，第三个参数为保存的文件路劲\n",
    "'''\n",
    "def save_result2csv(ys_submit,submit,csv_name):\n",
    "    all_customers = pd.DataFrame(submit[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "    submits_df = submit[['customer_id']]\n",
    "    submits_df['result'] = ys_submit\n",
    "    all_customers = pd.merge(all_customers,submits_df,on=['customer_id'],how='left',copy=False)\n",
    "    all_customers = all_customers.sort_values(['customer_id'])\n",
    "    all_customers['customer_id'] = all_customers['customer_id'].astype('int64')\n",
    "    all_customers['result'] = all_customers['result'].fillna(0)\n",
    "    all_customers.to_csv(csv_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n"
     ]
    }
   ],
   "source": [
    "print('Load data...')\n",
    "train = pd.read_csv('../Feature/train.csv',low_memory=False)\n",
    "submit = pd.read_csv('../Feature/submit12.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.pop('label')\n",
    "feature = [x for x in train.columns if x not in ['customer_id']]\n",
    "X = train[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)\n",
    "submit_df = submit[['customer_id']]\n",
    "X_submit0 = submit[feature]\n",
    "X_submit = X_submit0[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbdt_lr_train(X_train,y_train,X_test):\n",
    "\n",
    "    # 定义GBDT模型\n",
    "    gbdt = GradientBoostingClassifier(n_estimators=30, max_depth=8, verbose=5,max_features=0.8)\n",
    "\n",
    "    # 训练学习\n",
    "    gbdt.fit(X_train, y_train)\n",
    "\n",
    "    # 预测及AUC评测\n",
    "    y_pred_gbdt = gbdt.predict_proba(X_train)[:, 1]\n",
    "    gbdt_auc = metrics.roc_auc_score(y_train, y_pred_gbdt)\n",
    "    print('gbdt auc: %.5f' % gbdt_auc)\n",
    "    print('gbdt logloss: %.5f' % logloss(y_train,y_pred_gbdt))\n",
    "\n",
    "    # lr对原始特征样本模型训练\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)    # 预测及AUC评测\n",
    "    y_pred_test = lr.predict_proba(X_train)[:, 1]\n",
    "    lr_test_auc = metrics.roc_auc_score(y_train, y_pred_test)\n",
    "    print('基于原有特征的LR AUC: %.5f' % lr_test_auc)\n",
    "    print('基于原有特征的LR logloss: %.5f' % logloss(y_train,y_pred_test))\n",
    "\n",
    "    # GBDT编码原有特征\n",
    "    X_train_leaves = gbdt.apply(X_train)[:,:,0]\n",
    "    X_test_leaves = gbdt.apply(X_test)[:,:,0]\n",
    "\n",
    "    # 对所有特征进行ont-hot编码\n",
    "    (train_rows, cols) = X_train_leaves.shape\n",
    "\n",
    "    gbdtenc = OneHotEncoder()\n",
    "    X_trans = gbdtenc.fit_transform(np.concatenate((X_train_leaves, X_test_leaves), axis=0))\n",
    "\n",
    "    # 定义LR模型\n",
    "    lr = LogisticRegression(n_jobs=-1,verbose=5)\n",
    "    # lr对gbdt特征编码后的样本模型训练\n",
    "    lr.fit(X_trans[:train_rows, :], y_train)\n",
    "    # 预测及AUC评测\n",
    "    y_pred_gbdtlr1 = lr.predict_proba(X_trans[:train_rows, :])[:, 1]\n",
    "    gbdt_lr_auc1 = metrics.roc_auc_score(y_train, y_pred_gbdtlr1)\n",
    "    print('基于GBDT特征编码后的LR AUC: %.5f' % gbdt_lr_auc1)\n",
    "    print('基于GBDT特征编码后的LR logloss: %.5f' % logloss(y_train,y_pred_gbdtlr1))\n",
    "    \n",
    "    y_pred_res = lr.predict_proba(X_trans[train_rows:, :])[:, 1]\n",
    "    return y_pred_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9718            7.74m\n",
      "         2           0.9449            7.42m\n",
      "         3           0.9217            7.16m\n",
      "         4           0.9024            6.94m\n",
      "         5           0.8861            6.71m\n",
      "         6           0.8723            6.44m\n",
      "         7           0.8608            6.18m\n",
      "         8           0.8509            5.91m\n",
      "         9           0.8423            5.65m\n",
      "        10           0.8349            5.38m\n",
      "        11           0.8283            5.12m\n",
      "        12           0.8228            4.85m\n",
      "        13           0.8180            4.57m\n",
      "        14           0.8138            4.29m\n",
      "        15           0.8097            4.03m\n",
      "        16           0.8064            3.77m\n",
      "        17           0.8032            3.50m\n",
      "        18           0.8004            3.23m\n",
      "        19           0.7980            2.96m\n",
      "        20           0.7960            2.68m\n",
      "        21           0.7940            2.41m\n",
      "        22           0.7923            2.14m\n",
      "        23           0.7905            1.87m\n",
      "        24           0.7889            1.61m\n",
      "        25           0.7878            1.33m\n",
      "        26           0.7864            1.06m\n",
      "        27           0.7852           47.88s\n",
      "        28           0.7841           31.93s\n",
      "        29           0.7829           15.96s\n",
      "        30           0.7821            0.00s\n",
      "gbdt auc: 0.79983\n",
      "gbdt logloss: 0.58729\n",
      "基于原有特征的LR AUC: 0.60156\n",
      "基于原有特征的LR logloss: 0.75991\n",
      "[LibLinear]基于GBDT特征编码后的LR AUC: 0.80664\n",
      "基于GBDT特征编码后的LR logloss: 0.57250\n"
     ]
    }
   ],
   "source": [
    "y_preprob=gbdt_lr_train(X,y,X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9993982919856202\n",
      "min:  4.9135307938928126e-08\n",
      "mean:  0.29932285237014233\n",
      "var:  0.033054851061294195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show(y_preprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result2csv(y_preprob,submit,'../Res/res_gbdt_new12.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
