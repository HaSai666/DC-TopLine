{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ksama\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import datetime\n",
    "from tqdm import trange\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import warnings\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.linear_model import  *\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from xgboost import *\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.linear_model import  *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sympy import *\n",
    "from xgboost import plot_importance\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看结果的最大值，最小值，平均值\n",
    "def show(result):\n",
    "    print('max: ',str(max(result)))\n",
    "    print('min: ',str(min(result)))\n",
    "    print('mean: ',str((sum(result))/(len(result))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#官方的loss评估\n",
    "def logloss(y_true, y_pred,deta = 1.85, eps=1e-15):\n",
    "    # Prepare numpy array data\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    assert (len(y_true) and len(y_true) == len(y_pred))\n",
    "    # Clip y_pred between eps and 1-eps\n",
    "    p = np.clip(y_pred, eps, 1-eps)\n",
    "    loss = np.sum(- y_true * np.log(p) * deta - (1 - y_true) * np.log(1-p))\n",
    "    return loss / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "卡方特征选取\n",
    "\"\"\"\n",
    "def chi_square_test(X,y,select_k=10):\n",
    "    if select_k >= 1:\n",
    "        sel_ = SelectKBest(k=select_k).fit(X,y)\n",
    "        col = X.columns[sel_.get_support()]\n",
    "    elif 0 < select_k < 1:\n",
    "        sel_ = SelectPercentile(percentile=select_k*100).fit(X,y)\n",
    "        col = X.columns[sel_.get_support()]   \n",
    "    else:\n",
    "        raise ValueError(\"select_k must be a positive number\")  \n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "把结果保存成指定格式的文件\n",
    "示例：save_result2csv(y_submit,submit,'./round1_diac2019_test.csv')\n",
    "其中y_submit为模型输出结果，submit为读入数据时生成的一个变量，第三个参数为保存的文件路劲\n",
    "'''\n",
    "def save_result2csv(ys_submit,submit,csv_name):\n",
    "    all_customers = pd.DataFrame(trian[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "    submits_df = submit[['customer_id']]\n",
    "    submits_df['result'] = ys_submit\n",
    "    all_customers = pd.merge(all_customers,submits_df,on=['customer_id'],how='left',copy=False)\n",
    "    all_customers = all_customers.sort_values(['customer_id'])\n",
    "    all_customers['customer_id'] = all_customers['customer_id'].astype('int64')\n",
    "    all_customers['result'] = all_customers['result'].fillna(0)\n",
    "    all_customers.to_csv(csv_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Feature/train.csv',low_memory=False)\n",
    "submit = pd.read_csv('../Feature/submit12.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.pop('label')\n",
    "feature = [x for x in train.columns if x not in ['customer_id']]\n",
    "X = train[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['count', 'goods_price_mean', 'goods_price_min', 'goods_price_max',\n",
      "       'goods_price_sum', 'is_member_actived', 'customer_gender',\n",
      "       'order_month_count', 'goods_id_count', 'GDP', 'pay_deleta_time_last',\n",
      "       'pay_deleta_time_first', 'pay_deleta_time_mean', 'goods_list_time_mean',\n",
      "       'goods_list_time_last', 'goods_num', 'order_total_num',\n",
      "       'order_total_payment', 'customer_province_l', 'order_pay_date_last',\n",
      "       'long_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#第一次训练，利用卡方特征选取21个特征进行训练LGB和XGB\n",
    "x_columns = chi_square_test(X, y, 21)\n",
    "print(x_columns)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X[x_columns], y, test_size=0.25, random_state=42,stratify=y)\n",
    "submit_df = submit[['customer_id']]\n",
    "X_submit = submit[x_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [      0       1       2 ... 1368473 1368475 1368478]\n",
      "[[217501   1115]\n",
      " [ 52978   2102]]\n",
      "Accuracy : 0.8024\n",
      "AUC Score (Train): 0.790633\n",
      "logloss SCore: 0.601484\n",
      ">>> [      0       4       5 ... 1368476 1368477 1368478]\n",
      "[[217420   1070]\n",
      " [ 53304   1902]]\n",
      "Accuracy : 0.8013\n",
      "AUC Score (Train): 0.792224\n",
      "logloss SCore: 0.601541\n",
      ">>> [      1       2       3 ... 1368476 1368477 1368478]\n",
      "[[217143   1092]\n",
      " [ 53550   1911]]\n",
      "Accuracy : 0.8004\n",
      "AUC Score (Train): 0.792358\n",
      "logloss SCore: 0.604049\n",
      ">>> [      0       1       2 ... 1368476 1368477 1368478]\n",
      "[[217034   1177]\n",
      " [ 53435   2050]]\n",
      "Accuracy : 0.8005\n",
      "AUC Score (Train): 0.791532\n",
      "logloss SCore: 0.603770\n",
      ">>> [      0       1       2 ... 1368475 1368476 1368477]\n",
      "[[217195   1230]\n",
      " [ 53195   2075]]\n",
      "Accuracy : 0.8011\n",
      "AUC Score (Train): 0.790400\n",
      "logloss SCore: 0.603393\n"
     ]
    }
   ],
   "source": [
    "#5折 训练lgb 这里在数据层面增强了正样本比例，但没有更换loss function\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1234)\n",
    "y_pp_lgb = np.zeros(len(X_submit))\n",
    "y_pp_lgb_stacking = np.zeros(len(y_train))\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print ( \">>>\", train_index )\n",
    "    lightgbm = lgb.LGBMClassifier(learning_rate =0.01,\n",
    "                                 n_estimators=300,\n",
    "                                 max_depth=12,\n",
    "                                 min_child_weight=1,\n",
    "                                 eta = 0.01,\n",
    "                                 alpha = 0.01,\n",
    "                                 gamma=0.0,\n",
    "                                 subsample=0.7,\n",
    "                                 colsample_bytree=0.7,\n",
    "                                 nthread=6,\n",
    "                                 scale_pos_weight=1,\n",
    "                                 seed=66)\n",
    "    lightgbm_model = lightgbm.fit(X_train.iloc[train_index], y_train.iloc[train_index]) \n",
    "\n",
    "    y_pred = lightgbm_model.predict(X_train.iloc[test_index]) \n",
    "    y_predprob = lightgbm_model.predict_proba(X_train.iloc[test_index])[:, 1] \n",
    "    \n",
    "    y_pp_lgb_stacking[test_index] = y_predprob\n",
    "    \n",
    "    print(metrics.confusion_matrix(y_train.iloc[test_index].values, y_pred))\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_train.iloc[test_index].values, y_pred))  \n",
    "    auc = metrics.roc_auc_score(y_train.iloc[test_index], y_predprob)\n",
    "    print(\"AUC Score (Train): %f\" % auc) \n",
    "    loglossscore = logloss(y_train.iloc[test_index],y_predprob)\n",
    "    print(\"logloss SCore: %f\" %loglossscore)\n",
    "    \n",
    "    y_pp_lgb += lightgbm_model.predict_proba(X_submit)[:, 1] / n_splits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x = lightgbm_model.predict_proba(X[x_columns])[:,1]\n",
    "p_submit = y_pp_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = pd.DataFrame()\n",
    "X0 = X\n",
    "X0['p']=p_x\n",
    "X_train0, X_valid0, y_train0, y_valid0 = train_test_split(X0, y, test_size=0.25, random_state=42,stratify=y)\n",
    "submit_df = submit[['customer_id']]\n",
    "X_submit00 = submit[feature]\n",
    "X_submit01 = X_submit00[x_columns]\n",
    "X_submit01['p']=p_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [      0       1       2 ... 1368473 1368475 1368478]\n",
      "[[216068   2548]\n",
      " [ 50840   4240]]\n",
      "Accuracy : 0.8049\n",
      "AUC Score (Train): 0.795188\n",
      "logloss SCore: 0.599545\n",
      ">>> [      0       4       5 ... 1368476 1368477 1368478]\n",
      "[[215999   2491]\n",
      " [ 51006   4200]]\n",
      "Accuracy : 0.8045\n",
      "AUC Score (Train): 0.796046\n",
      "logloss SCore: 0.599296\n",
      ">>> [      1       2       3 ... 1368476 1368477 1368478]\n",
      "[[215738   2497]\n",
      " [ 51209   4252]]\n",
      "Accuracy : 0.8038\n",
      "AUC Score (Train): 0.796685\n",
      "logloss SCore: 0.602078\n",
      ">>> [      0       1       2 ... 1368476 1368477 1368478]\n",
      "[[215647   2564]\n",
      " [ 51313   4172]]\n",
      "Accuracy : 0.8032\n",
      "AUC Score (Train): 0.796157\n",
      "logloss SCore: 0.601606\n",
      ">>> [      0       1       2 ... 1368475 1368476 1368477]\n",
      "[[215714   2711]\n",
      " [ 51063   4207]]\n",
      "Accuracy : 0.8035\n",
      "AUC Score (Train): 0.794647\n",
      "logloss SCore: 0.601761\n"
     ]
    }
   ],
   "source": [
    "#8折 训练lgb 这里在数据层面增强了正样本比例，但没有更换loss function\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1234)\n",
    "y_pp_lgb0 = np.zeros(len(X_submit01))\n",
    "y_pp_lgb_stacking0 = np.zeros(len(y_train0))\n",
    "for train_index, test_index in kf.split(X_train0):\n",
    "    print ( \">>>\", train_index )\n",
    "    lightgbm0 = lgb.LGBMClassifier(learning_rate =0.01,\n",
    "                                 n_estimators=200,\n",
    "                                 max_depth=12,\n",
    "                                 min_child_weight=1,\n",
    "                                 eta = 0.01,\n",
    "                                 alpha = 0.01,\n",
    "                                 gamma=0.0,\n",
    "                                 subsample=0.7,\n",
    "                                 colsample_bytree=0.7,\n",
    "                                 nthread=6,\n",
    "                                 scale_pos_weight=1,\n",
    "                                 seed=66)\n",
    "    lightgbm_model0 = lightgbm0.fit(X_train0.iloc[train_index], y_train0.iloc[train_index]) \n",
    "\n",
    "    y_pred = lightgbm_model0.predict(X_train0.iloc[test_index]) \n",
    "    y_predprob = lightgbm_model0.predict_proba(X_train0.iloc[test_index])[:, 1] \n",
    "    \n",
    "    y_pp_lgb_stacking0[test_index] = y_predprob\n",
    "    \n",
    "    print(metrics.confusion_matrix(y_train0.iloc[test_index].values, y_pred))\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_train0.iloc[test_index].values, y_pred))  \n",
    "    auc = metrics.roc_auc_score(y_train0.iloc[test_index], y_predprob)\n",
    "    print(\"AUC Score (Train): %f\" % auc) \n",
    "    loglossscore = logloss(y_train0.iloc[test_index],y_predprob)\n",
    "    print(\"logloss SCore: %f\" %loglossscore)\n",
    "    \n",
    "    y_pp_lgb0 += lightgbm_model0.predict_proba(X_submit01)[:, 1] / n_splits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result2csv(y_pp_lgb0,submit,'../Res/res_new12.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2635/2635 [01:58<00:00, 22.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#把一年内购买次数超过10次的人，购买概率增加0.1\n",
    "res = pd.read_csv('../Res/res_new12.csv')\n",
    "id0=submit[\"customer_id\"][submit[\"count\"]>10]\n",
    "\n",
    "id1=np.array(id0)\n",
    "for i in trange(len(id1)):\n",
    "    res[\"result\"][res[\"customer_id\"]==id1[i]] +=0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../Res/res_new12_final.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
